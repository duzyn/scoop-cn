{
    "version": "0.12.9",
    "description": "Get up and running with large language models locally.",
    "homepage": "https://ollama.com/",
    "license": "MIT",
    "notes": "Ollama with deamon has been moved to 'extras/ollama-full'.",
    "suggest": {
        "Ollama Full": "scoop-cn/ollama-full"
    },
    "architecture": {
        "64bit": {
            "url": "https://gh-proxy.net/https://github.com/ollama/ollama/releases/download/v0.12.9/ollama-windows-amd64.zip",
            "hash": "089fb46562a9f8d4064581ac11ab73bccc3906674a807c754f78b2f20ff3e5c8"
        },
        "arm64": {
            "url": "https://gh-proxy.net/https://github.com/ollama/ollama/releases/download/v0.12.9/ollama-windows-arm64.zip",
            "hash": "700ef85fd28f576ddfc22f23e795147159b33f12d4ee0608248de6dce9beb8ae"
        }
    },
    "bin": "ollama.exe",
    "checkver": {
        "github": "https://github.com/ollama/ollama"
    },
    "autoupdate": {
        "architecture": {
            "64bit": {
                "url": "https://gh-proxy.net/https://github.com/ollama/ollama/releases/download/v$version/ollama-windows-amd64.zip"
            },
            "arm64": {
                "url": "https://gh-proxy.net/https://github.com/ollama/ollama/releases/download/v$version/ollama-windows-arm64.zip"
            }
        },
        "hash": {
            "url": "$baseurl/sha256sum.txt"
        }
    }
}
